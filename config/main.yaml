hydra:
  run:
    dir: ./outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}


defaults:
  - hyperparams/ft_transformer: ft_transformer
  - hyperparams/tabpfn_finetune: tabpfn_finetune_10k

output_dir: ${hydra:run.dir}
seed: 0
devices: [6, 7]
n_random_runs_per_dataset: 9                  # suggested: 500 

models:
  - TABPFN_FINETUNE
model_plot_names:
  - TabPFN Finetune 10k
benchmarks:
  - CATEGORICAL_CLASSIFICATION
  - NUMERICAL_CLASSIFICATION
  - CATEGORICAL_REGRESSION
  - NUMERICAL_REGRESSION
  - CATEGORICAL_CLASSIFICATION_LARGE
  - NUMERICAL_CLASSIFICATION_LARGE
  - CATEGORICAL_REGRESSION_LARGE
  - NUMERICAL_REGRESSION_LARGE
search_types:
  # - RANDOM
  - DEFAULT


openml_dataset_ids_to_ignore:
  # - 44140  # diamonds numerical regression  (missing benchmark values)
  # - 44059  # diamonds categorical regression (missing benchmark values)
  - 44135  # isolet numerical regression (613 features)
  - 44061  # mercedes_benz categorical regression (359 features)
  - 45041  # topo categorical regression (255 features)
  - 45046  # allstate_claims categorical regression (124 features)
  - 45019  # bioresponse numerical classification (419 features)


plotting:
  n_runs: 500                   # Number of runs to consider for plotting
  n_random_shuffles: 100         # Number of random shuffles for plotting the confidence boundaries
  confidence_bound: 0.90       # Confidence bounds ratio for plotting the confidence boundaries

  benchmark_models:   # Based on which models do we normalize the accuracy and R2
    - MLP
    - RESNET
    - SAINT
    - FT_TRANSFORMER
    - RANDOM_FOREST
    - XGBOOST
    - GRADIENT_BOOSTING_TREE