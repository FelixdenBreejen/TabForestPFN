batch_size: 
  value: 512
max_epochs:
  value: 300
optimizer:
  value: adamw
lr:
  distribution: log_uniform_values
  min: 1.e-5
  max: 1.e-3
  default: 1.e-4
weight_decay:
  distribution: log_uniform_values
  min: 1.e-6
  max: 1.e-3
  default: 1.e-5
lr_scheduler:
  values: [True, False]
  default: True
lr_scheduler_patience:
  value: 30
early_stopping_patience:
  value: 40


d_token:
  distribution: q_uniform
  min: 64
  max: 512
  default: 192
activation: 
  value: reglu
token_bias: 
  value: True
prenormalization: 
  value: True
kv_compression:
  values: [True, False]
  default: True
kv_compression_sharing:
  values: [headwise, key-value]
  default: headwise
initialization: 
  value: kaiming
n_layers:
  distribution: q_uniform
  min: 1
  max: 6
  default: 3
n_heads:
  value: 8
d_ffn_factor:
  distribution: uniform
  min: 0.667
  max: 2.333
  default: 1.333
ffn_dropout:
  distribution: uniform
  min: 0.0
  max: 0.5
  default: 0.1
attention_dropout:
  distribution: uniform
  min: 0.0
  max: 0.5
  default: 0.2
residual_dropout:
  distribution: 0.0
  min: 0.0
  max: 0.5
  default: 0.0
transformed_target:
  values: [False, True]
  default: True